# ServerProperties   #访问tomcat的端口和路径
server.port=8080
server.servlet.context-path=/community

# ThymeleafProperties    #模板引擎配置
spring.thymeleaf.cache=false

# DataSourceProperties   #数据库连接池
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/communtiy?characterEncoding=utf-8&useSSL=false&serverTimezone=Hongkong
spring.datasource.username=root
spring.datasource.password=root
spring.datasource.type=com.zaxxer.hikari.HikariDataSource
spring.datasource.hikari.maximum-pool-size=15
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.idle-timeout=30000

# MybatisProperties     #Mybatis配置 注意这里的配置只会对写在xml中的sql语句生效，不对注解上的sql语句生效
# mapper映射文件存放位置 注意这里的classpath本质是编译后的/community/target/classes/目录，/community/src/main/resources目录下文件都会被编译到该目录下，同时/community/src/main/java/目录下的源码也都会被编译到这里。
mybatis.mapper-locations=classpath:mapper/*.xml
# 映射表对应实体类所在包的包名
mybatis.type-aliases-package=com.nowcoder.community.entity
# 启用自增主键 在insertUser方法中，自增主键会回填到对象user中
mybatis.configuration.useGeneratedKeys=true
# 字段user_name与属性userName自动匹配
mybatis.configuration.mapUnderscoreToCamelCase=true

# 更新的日志配置在logback-spring.xml下
# logger     #日志 debug可以显示更详细的sql信息，方便调试
# 日志框架使用的是LogBack，这里配置的是日志输出的级别，目的是为了方便查看项目执行的SQL
#logging.level.com.nowcoder.community=warn
# 配置日志输出的目录，即将日志输出到指定目录下的指定名称文件中
#logging.file=d:/work/data/nowcoder/community.log

# Mailproperties
# 需要开启 smtp
spring.mail.host=smtp.qq.com
spring.mail.port=465
# 发件人的邮箱
spring.mail.username=1304642992@qq.com
# qq 邮箱的第三方授权码 并非个人密码
spring.mail.password=fkeytlwwnspcfehe
#开启ssl 否则 503 错误
spring.mail.properties.mail.smtp.ssl.enable=true

# community  这是自定义的属性（常量）
community.path.domain=http://localhost:8080
community.path.upload=d:/work/data/upload

# RedisProperties
# 共有16个数据库，选择使用哪个数据库
spring.redis.database=11
# 选择数据库所在ip地址
spring.redis.host=localhost
#选择数据库连接的端口
spring.redis.port=6379

# kafkaProperties
# 指定Kafka代理的地址和端口：Kafka代理运行在本地主机上，端口为9092。
spring.kafka.bootstrap-servers=localhost:9092
# 指定消费者所属的消费组ID：消费组是一组消费者的逻辑名称，共同处理来自Kafka主题的消息。
spring.kafka.consumer.group-id=test-consumer-group
# 指定是否启用消费者自动提交偏移量。如果设置为true，消费者将定期自动提交已处理消息的偏移量。如果设置为false，则需要手动提交偏移量。
spring.kafka.consumer.enable-auto-commit=true
# 指定自动提交偏移量的时间间隔（以毫秒为单位）。在指定的时间间隔内，消费者将自动提交已处理消息的偏移量。
spring.kafka.consumer.auto-commit-interval=3000

# 设置Kafka相关类的日志级别为WARN或更高级别，以取消INFO级别的日志输出
# 这两个配置，区别在于配置的粒度和生效范围，针对具体的日志记录器，只会影响到与org.apache.kafka和org.springframework.kafka对应的类的日志输出
logging.level.org.apache.kafka=warn
# logging.level.org.springframework.kafka=warn


# ElasticsearchProperties
spring.data.elasticsearch.cluster-name=nowcoder
spring.data.elasticsearch.cluster-nodes=127.0.0.1:9300